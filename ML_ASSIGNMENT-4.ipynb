{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1784803",
   "metadata": {},
   "source": [
    "# 1. What are the key tasks involved in getting ready to work with machine learning modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083afed",
   "metadata": {},
   "source": [
    "The key tasks involved in getting ready to work with machine learning modeling are:\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather and preprocess data.\n",
    "3. Perform exploratory data analysis (EDA).\n",
    "4. Engineer or select appropriate features.\n",
    "5. Split the data into training, validation, and testing sets.\n",
    "6. Choose a modeling approach.\n",
    "7. Train and evaluate the model.\n",
    "8. Validate and fine-tune the model.\n",
    "9. Finalize and deploy the model.\n",
    "10. Monitor and update the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2715fd",
   "metadata": {},
   "source": [
    "# 2. What are the different forms of data used in machine learning? Give a specific example for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd86a2d",
   "metadata": {},
   "source": [
    "Different forms of data used in machine learning include:\n",
    "\n",
    "1. Numerical Data: Data represented by numerical values.\n",
    "\n",
    "Example: House prices,Sensor readings.\n",
    "\n",
    "2. Categorical Data: Data with discrete categories or labels.\n",
    "\n",
    "Example: Email spam detection,Disease diagnosis.\n",
    "\n",
    "3. Text Data: Unstructured textual information.\n",
    "\n",
    "Example: Sentiment analysis,Text classification.\n",
    "\n",
    "4. Image Data: Visual information represented as pixels.\n",
    "\n",
    "Example: Object detection,Image classification.\n",
    "\n",
    "5. Time Series Data: Observations recorded over time.\n",
    "\n",
    "Example: Stock market prediction,Energy consumption forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5fab8",
   "metadata": {},
   "source": [
    "# 3. Distinguish:\n",
    "\n",
    "1. Numeric vs. categorical attributes\n",
    "\n",
    "2. Feature selection vs. dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e94c4",
   "metadata": {},
   "source": [
    "1. Numeric vs. categorical attributes:\n",
    "\n",
    "\n",
    "       Numeric attributes: Numeric attributes represent continuous or discrete numerical values. They can take on a wide range of values and can be used for mathematical operations. Examples of numeric attributes include age, height, temperature, or income.\n",
    "\n",
    "       attributes: Categorical attributes represent variables that fall into specific categories or groups. They are often represented by labels or symbols. Examples of categorical attributes include gender (male or female), color (red, blue, green), or product categories (electronics, clothing, furniture).\n",
    "\n",
    "The main difference between numeric and categorical attributes lies in the nature of the values they represent. Numeric attributes are quantifiable and allow for mathematical operations, while categorical attributes represent qualitative characteristics and are typically used for grouping or classification purposes.\n",
    "\n",
    "2. Feature selection vs. dimensionality reduction:\n",
    "\n",
    "\n",
    "       Feature selection: Feature selection is the process of selecting a subset of relevant features from the original set of features. It aims to identify and retain the most informative and discriminative features while discarding irrelevant or redundant ones. Feature selection methods help reduce the complexity of the model, improve model performance, and reduce overfitting. The selected features are used as inputs for the machine learning model.\n",
    "\n",
    "       Dimensionality reduction: Dimensionality reduction is the process of reducing the number of variables or features in a dataset while preserving the most important information. It aims to overcome the curse of dimensionality, where high-dimensional data can lead to computational and performance challenges. Dimensionality reduction techniques transform the original features into a lower-dimensional space by combining or projecting them. This helps to retain the most significant information while reducing noise and redundancy.\n",
    "\n",
    "The main difference between feature selection and dimensionality reduction is their focus. Feature selection aims to select the most relevant features from the original set, while dimensionality reduction focuses on transforming or compressing the data to a lower-dimensional representation. Feature selection retains the original features but discards some, while dimensionality reduction creates new features that represent a compressed version of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466799a",
   "metadata": {},
   "source": [
    "# 4. Make quick notes on any two of the following:\n",
    "\n",
    "1. The histogram\n",
    "\n",
    "2. Use a scatter plot\n",
    "\n",
    "3.PCA (Personal Computer Aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7546d03",
   "metadata": {},
   "source": [
    "1. Scatter plot:\n",
    "\n",
    "       A scatter plot is a graphical representation of data points in a two-dimensional space.\n",
    "       \n",
    "       It is used to visualize the relationship or correlation between two continuous variables.\n",
    "       \n",
    "       Each data point is plotted as a single point on the graph, with one variable represented on the x-axis and the other variable on the y-axis.\n",
    "       \n",
    "       Scatter plots are valuable for identifying trends, patterns, clusters, or outliers in the data.\n",
    "       \n",
    "       They can help determine the nature of the relationship between the variables, such as positive or negative correlation, linear or nonlinear association.\n",
    "       \n",
    "       Scatter plots are often used in exploratory data analysis, regression analysis, and understanding the interplay between variables in machine learning tasks.\n",
    "       \n",
    "       \n",
    "3. PCA (Principal Component Analysis):\n",
    "\n",
    "       PCA is a dimensionality reduction technique used to transform a high-dimensional dataset into a lower-dimensional space while retaining as much information as possible.\n",
    "       \n",
    "       It identifies the principal components, which are new variables that are linear combinations of the original features.\n",
    "       \n",
    "       The principal components are chosen in such a way that they capture the maximum variance in the data.\n",
    "       \n",
    "       PCA can be used for data visualization, noise reduction, feature extraction, and speeding up machine learning algorithms by reducing the input dimensionality.\n",
    "       \n",
    "       It helps in identifying the most important features that contribute significantly to the data's variation.\n",
    "       \n",
    "       PCA assumes that the data is linearly correlated and works well when the principal components exhibit meaningful patterns and the data follows a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93fd0ba",
   "metadata": {},
   "source": [
    "# 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cce6ab",
   "metadata": {},
   "source": [
    "It is necessary to investigate data to gain a deeper understanding of its characteristics, patterns, and relationships. Exploring the data helps in identifying potential issues, making informed decisions, and creating appropriate models or analyses. Here are reasons why investigating data is crucial:\n",
    "\n",
    "1. Identify data quality issues: Exploring data allows you to identify and address data quality problems such as missing values, outliers, or inconsistencies. It helps in ensuring the data is accurate, complete, and suitable for analysis.\n",
    "\n",
    "2. Understand data distribution and patterns: Investigating data helps in understanding the distribution of values and identifying any underlying patterns or trends. It enables you to make assumptions, determine appropriate modeling techniques, and validate assumptions for further analysis.\n",
    "\n",
    "3. Detect outliers and anomalies: Exploring data allows for the detection of outliers or anomalies that may require further investigation. Outliers can affect statistical analyses and machine learning models, and understanding their presence and potential causes is essential for accurate modeling.\n",
    "\n",
    "4. Identify relationships and correlations: Investigating data helps in uncovering relationships and correlations between variables. It enables the identification of potential predictors, dependencies, or associations, which can guide feature selection, model building, and decision-making processes.\n",
    "\n",
    "5. Validate assumptions and check data suitability: Exploring data helps in validating assumptions made for statistical analyses or machine learning models. It allows for the assessment of data suitability, such as checking for normality assumptions, linearity assumptions, or independence assumptions.\n",
    "\n",
    "Regarding the discrepancy in exploring qualitative and quantitative data:\n",
    "\n",
    "\n",
    "Exploring qualitative and quantitative data can differ due to the nature of the data itself. Qualitative data often requires different techniques and methods for exploration compared to quantitative data. Some key differences include:\n",
    "\n",
    "1. Techniques: Qualitative data exploration may involve techniques such as content analysis, thematic analysis, or narrative analysis. These techniques focus on identifying themes, patterns, or recurring ideas in textual or qualitative information. Quantitative data exploration typically involves descriptive statistics, visualization techniques, or inferential statistics to understand numerical patterns and relationships.\n",
    "\n",
    "2. Visualization: Qualitative data exploration may involve visualizing textual or qualitative data using techniques like word clouds, network diagrams, or concept maps. Quantitative data exploration typically involves visualizations like histograms, scatter plots, or box plots to understand numerical distributions and relationships.\n",
    "\n",
    "3. Focus: Qualitative data exploration often emphasizes understanding the nuances, context, and rich details of the data. It aims to uncover meanings and interpretations within the data. Quantitative data exploration focuses more on numerical patterns, trends, and statistical measures to describe and analyze the data.\n",
    "\n",
    "While the approaches to exploring qualitative and quantitative data differ, both are essential for gaining insights and making informed decisions in data analysis and research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cb4d6",
   "metadata": {},
   "source": [
    "# 6. What are the various histogram shapes? What exactly are ‘bins&#39;?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec06ef",
   "metadata": {},
   "source": [
    "\n",
    "Various histogram shapes include:\n",
    "\n",
    "1. Normal Distribution: Symmetrical bell-shaped curve.\n",
    "2. Skewed Distribution: Positively skewed (right-skewed) or negatively skewed (left-skewed) distribution.\n",
    "3. Uniform Distribution: Flat, rectangular shape.\n",
    "4. Bimodal Distribution: Two distinct peaks.\n",
    "5. Multimodal Distribution: Multiple peaks.\n",
    "\n",
    "Bins in a histogram are the intervals or ranges into which data is divided for visualization. They discretize continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1be60",
   "metadata": {},
   "source": [
    "# 7. How do we deal with data outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d3fbd",
   "metadata": {},
   "source": [
    "\n",
    "To deal with data outliers:\n",
    "\n",
    "1. Exclude outliers if they significantly skew results or violate analysis assumptions.\n",
    "2. Apply data transformations to reduce the impact of outliers.\n",
    "3. Use winsorization or truncation to limit the influence of extreme values.\n",
    "4. Impute outliers in missing data using appropriate techniques.\n",
    "5. Consider robust statistical methods that are less sensitive to outliers.\n",
    "6. Use domain knowledge to determine if outliers hold valuable information or require further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da02d61",
   "metadata": {},
   "source": [
    "\n",
    "Dealing with data outliers involves considering their impact on the analysis or model and deciding how to handle them. Here are some common approaches for handling data outliers:\n",
    "\n",
    "1. Analysis exclusion: In certain cases, outliers can significantly skew the results or violate assumptions of the analysis. In such situations, excluding the outliers from the analysis can be appropriate. However, it should be done with caution and based on solid justifications.\n",
    "\n",
    "2. Data transformation: Applying mathematical transformations to the data can reduce the influence of outliers. Common transformations include logarithmic, square root, or Box-Cox transformations. These transformations can help make the data more normally distributed and lessen the impact of extreme values.\n",
    "\n",
    "3. Winsorization or truncation: Winsorization replaces extreme values with values closer to the rest of the data. It limits the impact of outliers without completely removing them. Truncation sets a hard limit on the range of values, discarding extreme values beyond the set limit.\n",
    "\n",
    "4. Imputation: Outliers in missing data can be imputed using appropriate techniques. Instead of removing or ignoring outliers, missing values can be estimated using methods like mean imputation, regression imputation, or multiple imputations. Imputing outliers allows for a more complete dataset while minimizing their impact.\n",
    "\n",
    "5. Robust statistical methods: Using robust statistical methods that are less sensitive to outliers can be beneficial. Robust estimators, such as median instead of mean, or non-parametric methods, can provide more reliable estimates when dealing with outliers.\n",
    "\n",
    "6. Domain knowledge: Understanding the context and domain of the data is crucial. Outliers may hold valuable information or indicate genuine anomalies. It is important to consult subject matter experts or consider the unique characteristics of the data to determine if outliers should be treated differently or investigated further.\n",
    "\n",
    "Ultimately, the approach for dealing with data outliers depends on the specific dataset, the analysis or modeling task, and the goals of the analysis. Careful consideration should be given to the potential impact of outliers and the most appropriate strategy for handling them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11258e",
   "metadata": {},
   "source": [
    "# 8. What are the various central inclination measures? Why does mean vary too much from median in certain data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c458c1",
   "metadata": {},
   "source": [
    "Various central inclination measures are mean, median, and mode. The mean can vary significantly from the median in certain datasets due to the influence of outliers and skewed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0236654",
   "metadata": {},
   "source": [
    "# 9. Describe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8c9f3",
   "metadata": {},
   "source": [
    "A scatter plot is used to investigate the relationship between two continuous variables. It helps assess the nature of the relationship, identify outliers, detect clusters or groups, and identify trends or patterns within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b1399",
   "metadata": {},
   "source": [
    "A scatter plot is a graphical representation that displays the relationship between two continuous variables. It consists of data points plotted on a two-dimensional graph, with one variable represented on the x-axis and the other on the y-axis. Scatter plots are useful for investigating bivariate relationships and identifying patterns, trends, or correlations between variables. Here's how a scatter plot can be used for investigation:\n",
    "\n",
    "1. Relationship Assessment: Scatter plots help assess the nature of the relationship between two variables. By visually examining the pattern of the data points, you can determine if there is a positive, negative, or no apparent relationship between the variables. For example, if the data points generally follow an upward trend from left to right, it suggests a positive correlation.\n",
    "\n",
    "2. Outlier Detection: Scatter plots can be helpful in identifying outliers, which are extreme or unusual data points that deviate significantly from the overall pattern. Outliers may appear as data points that are far away from the bulk of the other points. By visually inspecting the scatter plot, you can spot potential outliers that lie far from the general trend or cluster of data points. Outliers can be indications of errors, anomalies, or interesting observations within the dataset.\n",
    "\n",
    "3. Cluster or Group Identification: Scatter plots can reveal clusters or groups within the data. By observing the distribution of data points, you may identify distinct clusters or subgroups that share similar characteristics or patterns. This can help in understanding different subsets of the data or identifying potential subpopulations.\n",
    "\n",
    "4. Trend Identification: Scatter plots can also highlight trends or patterns that may exist within the data. By examining the general direction of the data points, you can identify if there is a linear trend, a curvilinear relationship, or no clear trend at all. This information can guide further analysis or modeling decisions.\n",
    "\n",
    "In summary, scatter plots provide a visual representation of the relationship between two variables. They enable the identification of bivariate patterns, trends, outliers, and clusters, allowing for deeper exploration and analysis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b2ecb",
   "metadata": {},
   "source": [
    "# 10. Describe how cross-tabs can be used to figure out how two variables are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186848c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference  A  B\n",
      "Gender          \n",
      "Female      1  2\n",
      "Male        2  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female'],\n",
    "    'Age Group': ['18-25', '26-35', '18-25', '26-35', '26-35', '18-25'],\n",
    "    'Preference': ['A', 'B', 'B', 'A', 'A', 'B']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform cross-tabulation\n",
    "cross_tab = pd.crosstab(df['Gender'], df['Preference'])\n",
    "\n",
    "# Display the cross-tabulation\n",
    "print(cross_tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90baf93c",
   "metadata": {},
   "source": [
    "Cross-tabulation, also known as a contingency table or crosstab, is a statistical technique used to analyze the relationship between two categorical variables. It presents the frequencies or counts of the data points that fall into each combination of categories for the two variables. Cross-tabs can be used to figure out how two variables are related in the following ways:\n",
    "\n",
    "1. Frequency Distribution: Cross-tabs provide a clear overview of the distribution of data across the categories of both variables. It allows for the comparison of frequencies or counts for each combination of categories, helping to identify patterns or imbalances in the data.\n",
    "\n",
    "2. Relationship Assessment: By examining the cross-tabulation, you can evaluate the association between the two variables. It helps determine if there is a relationship, dependence, or association between the categories of the two variables. The presence or absence of patterns or deviations from expected frequencies can provide insights into the relationship between the variables.\n",
    "\n",
    "3. Hypothesis Testing: Cross-tabs can be used to conduct hypothesis tests to determine if there is a significant association between the variables. Statistical tests, such as the chi-square test, can be performed on the cross-tabulated data to assess the strength and significance of the relationship.\n",
    "\n",
    "4. Conditional Analysis: Cross-tabs allow for conditional analysis, where the relationship between the variables is examined within specific categories of a third variable. It helps uncover differences or similarities in the relationship based on different subgroups or conditions.\n",
    "\n",
    "5. Visualization: Cross-tabs can be visually represented using heat maps or stacked bar charts, making it easier to interpret the relationship between the variables. Visual representations can highlight patterns, disparities, or trends within the data.\n",
    "\n",
    "In summary, cross-tabs provide a comprehensive view of the relationship between two categorical variables. They help analyze frequency distributions, assess relationships, perform hypothesis testing, conduct conditional analysis, and visualize the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b708983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d79487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
